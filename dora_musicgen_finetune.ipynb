{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20b86724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create .jsonl from the extracted features, make a train/test split, and save in the right place.\n",
    "\n",
    "# set the following variable to True if you want to see a progress bar instead of the printed results:\n",
    "use_tqdm = False\n",
    "\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import librosa\n",
    "from pydub import AudioSegment\n",
    "import wave\n",
    "import re\n",
    "\n",
    "from functools import partial\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "tqdm = partial(tqdm, position=0, leave=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78796ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_labels = pd.read_csv(\"train_labels.csv\")\n",
    "test_labels = pd.read_csv(\"test_labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77cce1c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:20,  5.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# make sure the .jsonl has a place to go\n",
    "os.makedirs(\"content/audiocraft/egs/train_small\", exist_ok=True)\n",
    "\n",
    "\n",
    "train_len = 0\n",
    "\n",
    "dataset_path = \"data/wav_files/wav-48/\"\n",
    "\n",
    "with open(\"content/audiocraft/egs/train_small/data.jsonl\", \"w\") as train_file:\n",
    "    for filename, caption in tqdm(zip(train_labels[\"ytid\"], train_labels[\"caption\"])):\n",
    "\n",
    "        # get key and BPM\n",
    "        y, sr = librosa.load(os.path.join(dataset_path, f\"{filename}.wav\"))\n",
    "        tempo, _ = librosa.beat.beat_track(y=y, sr=sr)\n",
    "        chroma = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "        key = np.argmax(np.sum(chroma, axis=1))\n",
    "        key = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B'][key]\n",
    "        length = librosa.get_duration(y=y, sr=sr)\n",
    "\n",
    "        # populate json\n",
    "        entry = {\n",
    "            \"key\": f\"{key}\",\n",
    "            \"artist\": \"\",\n",
    "            \"sample_rate\": 44100,\n",
    "            \"file_extension\": \"wav\",\n",
    "            \"description\": caption,\n",
    "            \"keywords\": \"\",\n",
    "            \"duration\": length,\n",
    "            \"bpm\": \"\",\n",
    "            \"genre\": \"\",\n",
    "            \"title\": \"\",\n",
    "            \"name\": \"\",\n",
    "            \"instrument\": \"\",\n",
    "            \"moods\": \"\",\n",
    "            \"path\": os.path.join(dataset_path, f\"{filename}.wav\"),\n",
    "        }\n",
    "#         print(entry)\n",
    "\n",
    "        train_len += 1\n",
    "        train_file.write(json.dumps(entry) + '\\n')\n",
    "        \n",
    "        if train_len == 5:\n",
    "            break\n",
    "\n",
    "print(train_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6aa28f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:00,  5.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(\"content/audiocraft/egs/eval_small\", exist_ok=True)\n",
    "eval_len = 0\n",
    "with open(\"content/audiocraft/egs/eval_small/data.jsonl\", \"w\") as eval_file:\n",
    "    for filename, caption in tqdm(zip(test_labels[\"ytid\"], test_labels[\"caption\"])):\n",
    "\n",
    "        # get key and BPM\n",
    "        y, sr = librosa.load(os.path.join(dataset_path, f\"{filename}.wav\"))\n",
    "        tempo, _ = librosa.beat.beat_track(y=y, sr=sr)\n",
    "        chroma = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "        key = np.argmax(np.sum(chroma, axis=1))\n",
    "        key = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B'][key]\n",
    "        length = librosa.get_duration(y=y, sr=sr)\n",
    "\n",
    "        # populate json\n",
    "        entry = {\n",
    "            \"key\": f\"{key}\",\n",
    "            \"artist\": \"\",\n",
    "            \"sample_rate\": 44100,\n",
    "            \"file_extension\": \"wav\",\n",
    "            \"description\": caption,\n",
    "            \"keywords\": \"\",\n",
    "            \"duration\": length,\n",
    "            \"bpm\": \"\",\n",
    "            \"genre\": \"\",\n",
    "            \"title\": \"\",\n",
    "            \"name\": \"\",\n",
    "            \"instrument\": \"\",\n",
    "            \"moods\": \"\",\n",
    "            \"path\": os.path.join(dataset_path, f\"{filename}.wav\"),\n",
    "        }\n",
    "#         print(entry)\n",
    "\n",
    "        eval_len += 1\n",
    "        eval_file.write(json.dumps(entry) + '\\n')\n",
    "        if eval_len == 5:\n",
    "            break\n",
    "\n",
    "print(eval_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "56ec7691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear cuda mem for finetuning\n",
    "from numba import cuda\n",
    "device = cuda.get_current_device()\n",
    "device.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77f26f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: USER=yimt\n",
      "Dora directory: other_dir\n",
      "/opt/conda/lib/python3.10/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[\u001b[36m12-03 23:56:03\u001b[0m][\u001b[34mdora.distrib\u001b[0m][\u001b[32mINFO\u001b[0m] - world_size is 1, skipping init.\u001b[0m\n",
      "[\u001b[36m12-03 23:56:03\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Instantiating solver MusicGenSolver for XP 1894a354\u001b[0m\n",
      "[\u001b[36m12-03 23:56:03\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - All XP logs are stored in /home/thomasyim/cs229-music/other_dir/xps/1894a354\u001b[0m\n",
      "/opt/conda/lib/python3.10/site-packages/flashy/loggers/tensorboard.py:47: UserWarning: tensorboard package was not found: use pip install tensorboard\n",
      "  warnings.warn(\"tensorboard package was not found: use pip install tensorboard\")\n",
      "[\u001b[36m12-03 23:56:03\u001b[0m][\u001b[34maudiocraft.solvers.builders\u001b[0m][\u001b[32mINFO\u001b[0m] - Loading audio data split evaluate: /home/thomasyim/cs229-music/content/audiocraft/egs/eval\u001b[0m\n",
      "[\u001b[36m12-03 23:56:03\u001b[0m][\u001b[34maudiocraft.solvers.builders\u001b[0m][\u001b[32mINFO\u001b[0m] - Loading audio data split generate: /home/thomasyim/cs229-music/content/audiocraft/egs/train\u001b[0m\n",
      "[\u001b[36m12-03 23:56:04\u001b[0m][\u001b[34maudiocraft.solvers.builders\u001b[0m][\u001b[32mINFO\u001b[0m] - Loading audio data split train: /home/thomasyim/cs229-music/content/audiocraft/egs/train\u001b[0m\n",
      "[\u001b[36m12-03 23:56:04\u001b[0m][\u001b[34maudiocraft.solvers.builders\u001b[0m][\u001b[32mINFO\u001b[0m] - Loading audio data split valid: /home/thomasyim/cs229-music/content/audiocraft/egs/eval\u001b[0m\n",
      "[\u001b[36m12-03 23:56:04\u001b[0m][\u001b[34mroot\u001b[0m][\u001b[32mINFO\u001b[0m] - Getting pretrained compression model from HF facebook/encodec_32khz\u001b[0m\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/models/encodec/modeling_encodec.py:124: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.register_buffer(\"padding_total\", torch.tensor(kernel_size - stride, dtype=torch.int64), persistent=False)\n",
      "[\u001b[36m12-03 23:56:05\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Compression model has 4 codebooks with 2048 cardinality, and a framerate of 50\u001b[0m\n",
      "[\u001b[36m12-03 23:56:05\u001b[0m][\u001b[34maudiocraft.modules.conditioners\u001b[0m][\u001b[32mINFO\u001b[0m] - T5 will be evaluated with autocast as float32\u001b[0m\n",
      "[\u001b[36m12-03 23:56:11\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Model hash: 84d640e215de7863e944e465549d3e2e5faa07eb\u001b[0m\n",
      "[\u001b[36m12-03 23:56:11\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Initializing EMA on the model with decay = 0.99 every 10 updates\u001b[0m\n",
      "[\u001b[36m12-03 23:56:11\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Model size: 420.37 M params\u001b[0m\n",
      "[\u001b[36m12-03 23:56:11\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Base memory usage, with model, grad and optim: 6.73 GB\u001b[0m\n",
      "[\u001b[36m12-03 23:56:11\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Restoring weights and history.\u001b[0m\n",
      "[\u001b[36m12-03 23:56:11\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Loading a pretrained model. Ignoring 'load_best' and 'ignore_state_keys' params.\u001b[0m\n",
      "[\u001b[36m12-03 23:56:11\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Checkpoint source is not the current xp: Load state_dict from best state.\u001b[0m\n",
      "[\u001b[36m12-03 23:56:11\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Ignoring keys when loading best []\u001b[0m\n",
      "[\u001b[36m12-03 23:56:11\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Loading state_dict from best state.\u001b[0m\n",
      "[\u001b[36m12-03 23:56:13\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Re-initializing EMA from best state\u001b[0m\n",
      "[\u001b[36m12-03 23:56:13\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Initializing EMA on the model with decay = 0.99 every 10 updates\u001b[0m\n",
      "[\u001b[36m12-03 23:56:16\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Model hash: 776d041cbbcb8973c4968782a79f9bb63b53a727\u001b[0m\n",
      "/home/thomasyim/audiocraft/audiocraft/solvers/musicgen.py:264: UserWarning: Up to version 1.0.1, the _prepare_tokens_and_attributes was evaluated with `torch.no_grad()`. This is inconsistent with how model were trained in the MusicGen paper. We removed the `torch.no_grad()` in version 1.1.0. Small changes to the final performance are expected. Really sorry about that.\n",
      "  warnings.warn(\n",
      "[\u001b[36m12-03 23:56:28\u001b[0m][\u001b[34maudiocraft.modules.codebooks_patterns\u001b[0m][\u001b[32mINFO\u001b[0m] - New pattern, time steps: 1500, sequence steps: 1504\u001b[0m\n",
      "/opt/conda/lib/python3.10/site-packages/torch/cuda/__init__.py:866: UserWarning: Synchronization debug mode is a prototype feature and does not yet detect all synchronizing operations (Triggered internally at ../torch/csrc/cuda/Module.cpp:816.)\n",
      "  torch._C._cuda_set_sync_debug_mode(debug_mode)\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/models/encodec/modeling_encodec.py:148: UserWarning: called a synchronizing CUDA operation (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:147.)\n",
      "  max_pad = max(padding_left, padding_right)\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/models/encodec/modeling_encodec.py:150: UserWarning: called a synchronizing CUDA operation (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:147.)\n",
      "  if length <= max_pad:\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/models/encodec/modeling_encodec.py:153: UserWarning: called a synchronizing CUDA operation (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:147.)\n",
      "  padded = nn.functional.pad(hidden_states, paddings, mode, value)\n",
      "/home/thomasyim/audiocraft/audiocraft/solvers/musicgen.py:238: UserWarning: called a synchronizing CUDA operation (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:147.)\n",
      "  ce_targets = targets_k[mask_k]\n",
      "/home/thomasyim/audiocraft/audiocraft/solvers/musicgen.py:239: UserWarning: called a synchronizing CUDA operation (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:147.)\n",
      "  ce_logits = logits_k[mask_k]\n",
      "Error opening file /home/thomasyim/cs229-music/data/wav_files/wav-48/W58kioYp1Ms.wav: AssertionError()\n",
      "[\u001b[36m12-03 23:57:51\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 1 | 100/1000 | 1.19 it/sec | lr 9.55E-05 | grad_norm INF | grad_scale 18492.832 | ce 2.537 | ppl 14.500\u001b[0m\n",
      "Error opening file /home/thomasyim/cs229-music/data/wav_files/wav-48/W58kioYp1Ms.wav: AssertionError()\n",
      "[\u001b[36m12-03 23:59:15\u001b[0m][\u001b[34mflashy.solver\u001b[0m][\u001b[32mINFO\u001b[0m] - Train | Epoch 1 | 200/1000 | 1.20 it/sec | lr 9.98E-05 | grad_norm 4.639E+00 | grad_scale 16384.000 | ce 2.462 | ppl 12.150\u001b[0m\n",
      "Error opening file /home/thomasyim/cs229-music/data/wav_files/wav-48/W58kioYp1Ms.wav: AssertionError()\n"
     ]
    }
   ],
   "source": [
    "%env USER=yimt\n",
    "# CHANGE THIS\n",
    "\n",
    "!\n",
    "\n",
    "command = (\n",
    "    \"HYDRA_FULL_ERROR=1 AUDIOCRAFT_DORA_DIR=other_dir dora -P audiocraft run\"\n",
    "    \" solver=musicgen/musicgen_base_32khz\"\n",
    "    \" model/lm/model_scale=small\"\n",
    "    \" continue_from=//pretrained/facebook/musicgen-small\"\n",
    "    \" conditioner=text2music\"\n",
    "    \" dset=audio/finetune\"\n",
    "    \" dataset.num_workers=2\"\n",
    "    \" dataset.valid.num_samples=1\"\n",
    "    \" dataset.batch_size=1\" # CHANGE THIS\n",
    "    \" schedule.cosine.warmup=8\"\n",
    "    \" optim.optimizer=adamw\" # uses dadaw by default, which is worse for single-gpu runs\n",
    "    \" optim.lr=1e-4\"\n",
    "    \" optim.epochs=5\" # stops training after 5 epochs- change this\n",
    "    \" optim.updates_per_epoch=1000\" # 2000 by default, change this if you want checkpoints quicker ig\n",
    "    \" optim.adam.weight_decay=0.01\"\n",
    "    \" generate.lm.prompted_samples=False\" # skip super long generate step\n",
    "    \" generate.lm.gen_gt_samples=True\"\n",
    "    \" +output_dir=dora_output\"\n",
    ")\n",
    "\n",
    "!{command}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464c43e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c302fbb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dora directory: /tmp/audiocraft_yimt\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: '/checkpoints'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/lib/python3.10/pathlib.py:1175\u001b[0m, in \u001b[0;36mPath.mkdir\u001b[0;34m(self, mode, parents, exist_ok)\u001b[0m\n\u001b[1;32m   1174\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1175\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_accessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1176\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/checkpoints/my_audio_lm'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01maudiocraft\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m export\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01maudiocraft\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train\n\u001b[0;32m----> 3\u001b[0m \u001b[43mexport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexport_pretrained_compression_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfacebook/encodec_32khz\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/checkpoints/my_audio_lm/compression_state_dict.bin\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/audiocraft/audiocraft/utils/export.py:57\u001b[0m, in \u001b[0;36mexport_pretrained_compression_model\u001b[0;34m(pretrained_encodec, out_file)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m     pkg \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     53\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpretrained\u001b[39m\u001b[38;5;124m'\u001b[39m: pretrained_encodec,\n\u001b[1;32m     54\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexported\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     55\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mversion\u001b[39m\u001b[38;5;124m'\u001b[39m: __version__,\n\u001b[1;32m     56\u001b[0m     }\n\u001b[0;32m---> 57\u001b[0m \u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout_file\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(pkg, out_file)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/pathlib.py:1179\u001b[0m, in \u001b[0;36mPath.mkdir\u001b[0;34m(self, mode, parents, exist_ok)\u001b[0m\n\u001b[1;32m   1177\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parents \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparent \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m   1178\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m-> 1179\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1180\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmkdir(mode, parents\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, exist_ok\u001b[38;5;241m=\u001b[39mexist_ok)\n\u001b[1;32m   1181\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m   1182\u001b[0m     \u001b[38;5;66;03m# Cannot rely on checking for EEXIST, since the operating system\u001b[39;00m\n\u001b[1;32m   1183\u001b[0m     \u001b[38;5;66;03m# could give priority to other errors like EACCES or EROFS\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/pathlib.py:1175\u001b[0m, in \u001b[0;36mPath.mkdir\u001b[0;34m(self, mode, parents, exist_ok)\u001b[0m\n\u001b[1;32m   1171\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1172\u001b[0m \u001b[38;5;124;03mCreate a new directory at this given path.\u001b[39;00m\n\u001b[1;32m   1173\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1174\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1175\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_accessor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1176\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m:\n\u001b[1;32m   1177\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parents \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparent \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m:\n",
      "\u001b[0;31mPermissionError\u001b[0m: [Errno 13] Permission denied: '/checkpoints'"
     ]
    }
   ],
   "source": [
    "from audiocraft.utils import export\n",
    "from audiocraft import train\n",
    "export.export_pretrained_compression_model('facebook/encodec_32khz', '/checkpoints/my_audio_lm/compression_state_dict.bin')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "344f783f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!export AUDIOCRAFT_DORA_DIR=\"other_dir\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d79a8bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n"
     ]
    }
   ],
   "source": [
    "!echo $AUDIOCRAFT_DORA_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7519c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from audiocraft.utils import export\n",
    "from audiocraft import train\n",
    "xp = train.main.get_xp_from_sig('0bd6914e')\n",
    "print(xp.folder)\n",
    "# export.export_lm(xp.folder / 'checkpoint.th', '/checkpoints/my_audio_lm/state_dict.bin')\n",
    "# # You also need to bundle the EnCodec model you used !!\n",
    "# ## Case 1) you trained your own\n",
    "# xp_encodec = train.main.get_xp_from_sig('SIG_OF_ENCODEC')\n",
    "# export.export_encodec(xp_encodec.folder / 'checkpoint.th', '/checkpoints/my_audio_lm/compression_state_dict.bin')\n",
    "# ## Case 2) you used a pretrained model. Give the name you used without the //pretrained/ prefix.\n",
    "# ## This will actually not dump the actual model, simply a pointer to the right model to download.\n",
    "# export.export_pretrained_compression_model('facebook/encodec_32khz', '/checkpoints/my_audio_lm/compression_state_dict.bin')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8b2f5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
