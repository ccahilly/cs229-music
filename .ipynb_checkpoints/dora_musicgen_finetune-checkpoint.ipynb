{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "20b86724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create .jsonl from the extracted features, make a train/test split, and save in the right place.\n",
    "\n",
    "# set the following variable to True if you want to see a progress bar instead of the printed results:\n",
    "use_tqdm = False\n",
    "\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import librosa\n",
    "from pydub import AudioSegment\n",
    "import wave\n",
    "import re\n",
    "\n",
    "from functools import partial\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "tqdm = partial(tqdm, position=0, leave=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "78796ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_labels = pd.read_csv(\"train_labels.csv\")\n",
    "test_labels = pd.read_csv(\"test_labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "77cce1c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4063it [08:05,  8.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# make sure the .jsonl has a place to go\n",
    "os.makedirs(\"content/audiocraft/egs/train\", exist_ok=True)\n",
    "os.makedirs(\"content/audiocraft/egs/eval\", exist_ok=True)\n",
    "\n",
    "train_len = 0\n",
    "eval_len = 0\n",
    "\n",
    "dataset_path = \"data/wav_files/wav-48/\"\n",
    "\n",
    "with open(\"content/audiocraft/egs/train/data.jsonl\", \"w\") as train_file:\n",
    "    for filename, caption in tqdm(zip(train_labels[\"ytid\"], train_labels[\"caption\"])):\n",
    "\n",
    "        # get key and BPM\n",
    "        y, sr = librosa.load(os.path.join(dataset_path, f\"{filename}.wav\"))\n",
    "        tempo, _ = librosa.beat.beat_track(y=y, sr=sr)\n",
    "        chroma = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "        key = np.argmax(np.sum(chroma, axis=1))\n",
    "        key = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B'][key]\n",
    "        length = librosa.get_duration(y=y, sr=sr)\n",
    "\n",
    "        # populate json\n",
    "        entry = {\n",
    "            \"key\": f\"{key}\",\n",
    "            \"artist\": \"\",\n",
    "            \"sample_rate\": 44100,\n",
    "            \"file_extension\": \"wav\",\n",
    "            \"description\": caption,\n",
    "            \"keywords\": \"\",\n",
    "            \"duration\": length,\n",
    "            \"bpm\": \"\",\n",
    "            \"genre\": \"\",\n",
    "            \"title\": \"\",\n",
    "            \"name\": \"\",\n",
    "            \"instrument\": \"\",\n",
    "            \"moods\": \"\",\n",
    "            \"path\": os.path.join(dataset_path, f\"{filename}.wav\"),\n",
    "        }\n",
    "#         print(entry)\n",
    "\n",
    "        train_len += 1\n",
    "        train_file.write(json.dumps(entry) + '\\n')\n",
    "\n",
    "print(train_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6aa28f1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1016it [02:11,  7.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "with open(\"content/audiocraft/egs/eval/data.jsonl\", \"w\") as eval_file:\n",
    "    for filename, caption in tqdm(zip(test_labels[\"ytid\"], test_labels[\"caption\"])):\n",
    "\n",
    "        # get key and BPM\n",
    "        y, sr = librosa.load(os.path.join(dataset_path, f\"{filename}.wav\"))\n",
    "        tempo, _ = librosa.beat.beat_track(y=y, sr=sr)\n",
    "        chroma = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "        key = np.argmax(np.sum(chroma, axis=1))\n",
    "        key = ['C', 'C#', 'D', 'D#', 'E', 'F', 'F#', 'G', 'G#', 'A', 'A#', 'B'][key]\n",
    "        length = librosa.get_duration(y=y, sr=sr)\n",
    "\n",
    "        # populate json\n",
    "        entry = {\n",
    "            \"key\": f\"{key}\",\n",
    "            \"artist\": \"\",\n",
    "            \"sample_rate\": 44100,\n",
    "            \"file_extension\": \"wav\",\n",
    "            \"description\": caption,\n",
    "            \"keywords\": \"\",\n",
    "            \"duration\": length,\n",
    "            \"bpm\": \"\",\n",
    "            \"genre\": \"\",\n",
    "            \"title\": \"\",\n",
    "            \"name\": \"\",\n",
    "            \"instrument\": \"\",\n",
    "            \"moods\": \"\",\n",
    "            \"path\": os.path.join(dataset_path, f\"{filename}.wav\"),\n",
    "        }\n",
    "#         print(entry)\n",
    "\n",
    "        eval_len += 1\n",
    "        eval_file.write(json.dumps(entry) + '\\n')\n",
    "\n",
    "print(eval_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "56ec7691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear cuda mem for finetuning\n",
    "from numba import cuda\n",
    "device = cuda.get_current_device()\n",
    "device.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e77f26f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: USER=yimt\n",
      "Dora directory: /tmp/audiocraft_yimt\n",
      "/opt/conda/lib/python3.10/site-packages/hydra/_internal/hydra.py:119: UserWarning: Future Hydra versions will no longer change working directory at job runtime by default.\n",
      "See https://hydra.cc/docs/1.2/upgrades/1.1_to_1.2/changes_to_job_working_dir/ for more information.\n",
      "  ret = run_job(\n",
      "[\u001b[36m12-03 10:16:45\u001b[0m][\u001b[34mdora.distrib\u001b[0m][\u001b[32mINFO\u001b[0m] - world_size is 1, skipping init.\u001b[0m\n",
      "Error executing job with overrides: ['solver=musicgen/musicgen_base_32khz', 'model/lm/model_scale=small', 'continue_from=//pretrained/facebook/musicgen-small', 'conditioner=text2music', 'dset=audio/finetune', 'dataset.num_workers=2', 'dataset.valid.num_samples=1', 'dataset.batch_size=1', 'schedule.cosine.warmup=8', 'optim.optimizer=adamw', 'optim.lr=1e-4', 'optim.epochs=5', 'optim.updates_per_epoch=1000', 'optim.adam.weight_decay=0.01', 'generate.lm.prompted_samples=False', 'generate.lm.gen_gt_samples=True']\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/bin/dora\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dora/__main__.py\", line 170, in main\n",
      "    args.action(args, main)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dora/run.py\", line 69, in run_action\n",
      "    main()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dora/main.py\", line 86, in __call__\n",
      "    return self._main()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/dora/hydra.py\", line 228, in _main\n",
      "    return hydra.main(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/hydra/main.py\", line 94, in decorated_main\n",
      "    _run_hydra(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 394, in _run_hydra\n",
      "    _run_app(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 457, in _run_app\n",
      "    run_and_report(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 223, in run_and_report\n",
      "    raise ex\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 220, in run_and_report\n",
      "    return func()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/hydra/_internal/utils.py\", line 458, in <lambda>\n",
      "    lambda: hydra.run(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/hydra/_internal/hydra.py\", line 132, in run\n",
      "    _ = ret.return_value\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/hydra/core/utils.py\", line 260, in return_value\n",
      "    raise self._return_value\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/hydra/core/utils.py\", line 186, in run_job\n",
      "    ret.return_value = task_function(task_cfg)\n",
      "  File \"/home/thomasyim/audiocraft/audiocraft/train.py\", line 139, in main\n",
      "    solver = get_solver(cfg)\n",
      "  File \"/home/thomasyim/audiocraft/audiocraft/train.py\", line 47, in get_solver\n",
      "    resolve_config_dset_paths(cfg)\n",
      "  File \"/home/thomasyim/audiocraft/audiocraft/train.py\", line 33, in resolve_config_dset_paths\n",
      "    for key, value in cfg.datasource.items():\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/omegaconf/dictconfig.py\", line 359, in __getattr__\n",
      "    self._format_and_raise(key=key, value=None, cause=e)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/omegaconf/base.py\", line 231, in _format_and_raise\n",
      "    format_and_raise(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/omegaconf/_utils.py\", line 819, in format_and_raise\n",
      "    _raise(ex, cause)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/omegaconf/_utils.py\", line 797, in _raise\n",
      "    raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/omegaconf/dictconfig.py\", line 351, in __getattr__\n",
      "    return self._get_impl(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/omegaconf/dictconfig.py\", line 442, in _get_impl\n",
      "    node = self._get_child(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/omegaconf/basecontainer.py\", line 73, in _get_child\n",
      "    child = self._get_node(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/omegaconf/dictconfig.py\", line 475, in _get_node\n",
      "    self._validate_get(key)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/omegaconf/dictconfig.py\", line 164, in _validate_get\n",
      "    self._format_and_raise(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/omegaconf/base.py\", line 231, in _format_and_raise\n",
      "    format_and_raise(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/omegaconf/_utils.py\", line 899, in format_and_raise\n",
      "    _raise(ex, cause)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/omegaconf/_utils.py\", line 797, in _raise\n",
      "    raise ex.with_traceback(sys.exc_info()[2])  # set env var OC_CAUSE=1 for full trace\n",
      "omegaconf.errors.ConfigAttributeError: Key 'datasource' is not in struct\n",
      "    full_key: datasource\n",
      "    object_type=dict\n"
     ]
    }
   ],
   "source": [
    "%env USER=yimt\n",
    "# CHANGE THIS\n",
    "\n",
    "!\n",
    "\n",
    "command = (\n",
    "    \"HYDRA_FULL_ERROR=1 dora -P audiocraft run\"\n",
    "    \" solver=musicgen/musicgen_base_32khz\"\n",
    "    \" model/lm/model_scale=small\"\n",
    "    \" continue_from=//pretrained/facebook/musicgen-small\"\n",
    "    \" conditioner=text2music\"\n",
    "    \" dset=audio/random\"\n",
    "    \" dataset.num_workers=2\"\n",
    "    \" dataset.valid.num_samples=1\"\n",
    "    \" dataset.batch_size=1\" # CHANGE THIS\n",
    "    \" schedule.cosine.warmup=8\"\n",
    "    \" optim.optimizer=adamw\" # uses dadaw by default, which is worse for single-gpu runs\n",
    "    \" optim.lr=1e-4\"\n",
    "    \" optim.epochs=5\" # stops training after 5 epochs- change this\n",
    "    \" optim.updates_per_epoch=1000\" # 2000 by default, change this if you want checkpoints quicker ig\n",
    "    \" optim.adam.weight_decay=0.01\"\n",
    "    \" generate.lm.prompted_samples=False\" # skip super long generate step\n",
    "    \" generate.lm.gen_gt_samples=True\"\n",
    ")\n",
    "\n",
    "!{command}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464c43e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
